
precision highp float;

layout (local_size_x_id = 0, local_size_y_id = 1, local_size_z = 1) in;
layout (set = 0, binding = 0, rgba32f) uniform image2D targetImage;
layout (set = 1, binding = 0, rgba32f) uniform readonly image2D sourceImage;

layout(set = 2, binding = 0) uniform UniformCameraObject {
    mat4 view;
    mat4 proj;
    vec4 cameraPosition;
    vec4 cameraParams;
} camera;

layout(set = 2, binding = 1) uniform UniformCameraObjectPrev {
    mat4 view;
    mat4 proj;
    vec4 cameraPosition;
} cameraPrev;

// all of these components are calculated in SkyManager.h/.cpp
layout(set = 2, binding = 2) uniform UniformSunObject {   
    vec4 location;
    vec4 direction;
    vec4 color;
    mat4 directionBasis;
    float intensity;
} sun;

// note: a lot of sky constants are stored/precalculated in SkyManager.h / .cpp
layout(set = 2, binding = 3) uniform UniformSkyObject {  
    vec4 betaR;
    vec4 betaV;
    vec4 wind;
    float mie_directional;
} sky;

struct Intersection {
    vec3 normal;
    vec3 point;
    bool valid;
    float t;
};

#define ATMOSPHERE_RADIUS 2000000.0

#define EPSILON 0.0001
#define PI 3.14159265
#define E 2.718281828459


// Compute sphere intersection
Intersection raySphereIntersection(in vec3 ro, in vec3 rd, in vec4 sphere) {
	Intersection isect;
    isect.valid = false;
    isect.point = vec3(0);
    isect.normal = vec3(0, 1, 0);
    
    // no rotation, only uniform scale, always a sphere
    ro -= sphere.xyz;
    ro /= sphere.w;
    
    float A = dot(rd, rd);
    float B = 2.0 * dot(rd, ro);
    float C = dot(ro, ro) - 0.25;
    float discriminant = B * B - 4.0 * A * C;
    
    if (discriminant < 0.0) return isect;
    float t = (-sqrt(discriminant) - B) / A * 0.5;
    if (t < 0.0) t = (sqrt(discriminant) - B) / A * 0.5;
    
    if (t >= 0.0) {
        isect.valid = true;
    	vec3 p = vec3(ro + rd * t);
        isect.normal = normalize(p);
        p *= sphere.w;
        p += sphere.xyz;
        isect.point = p;
        isect.t = length(p - ro);
    }
    
    return isect;
}



void main() {
    // shader is dispatched at full resolution
    ivec2 dim = imageSize(sourceImage);
    vec2 uv = vec2(gl_GlobalInvocationID.xy) / dim;
    vec4 sourceColor = vec4(0);

    /// Cast a ray
    // Compute screen space point from UVs
    vec2 screenPoint = uv * 2.0 - 1.0;

    // Extract camera information from uniform
    vec3 camLook = vec3(camera.view[0][2], camera.view[1][2], camera.view[2][2]);
    vec3 camRight = vec3(camera.view[0][0], camera.view[1][0], camera.view[2][0]);
    vec3 camUp = vec3(camera.view[0][1], camera.view[1][1], camera.view[2][1]);

    // Compute ray direction
    vec3 cameraPos = camera.cameraPosition.xyz;
    vec3 refPoint = cameraPos - camLook;

    const float tanFovy = 0.4142135; // TODO link camera uniform
    vec3 p = refPoint + camera.cameraParams.x * screenPoint.x * camera.cameraParams.y * camRight - screenPoint.y * camera.cameraParams.y * camUp;
    vec3 rayDirection = normalize(p - cameraPos);

    /// Raytrace the scene (a sphere, to become the atmosphere)
    vec3 earthCenter = cameraPos;
    earthCenter.y = -ATMOSPHERE_RADIUS * 0.5 * 0.995;
    vec4 atmosphereSphereInner = vec4(earthCenter, ATMOSPHERE_RADIUS);

    // intersection of sphere in world space
    vec3 intersectionPos = raySphereIntersection(cameraPos, rayDirection, atmosphereSphereInner).point;
    
    // position of intersection in old View space
    // now intersection can be expressed in terms of right, up, look
    // (faster to just use direction but does not account for position)
    intersectionPos = (cameraPrev.view * vec4(intersectionPos, 1.0)).xyz;

    // view space direction
    vec3 oldCamRayDir = normalize(intersectionPos);
    //sourceColor.rgb = rayDirection * 0.5 + 0.5;

    // de-normalize the ray: -> <u, v, 1> in R U F basis
    oldCamRayDir /= -oldCamRayDir.z;
    float oldU = oldCamRayDir.x / camera.cameraParams.y / camera.cameraParams.x;
    oldU = oldU * 0.5 + 0.5;
    float oldV = -oldCamRayDir.y / camera.cameraParams.y;
    oldV = oldV * 0.5 + 0.5;
    vec2 oldUV = vec2(oldU, oldV);
    vec2 blurVec = oldUV - uv;

    // take n samples for motion blur
    
    for (int s = 0; s < 10; ++s) {
        vec2 blurOffset = blurVec * (float(s) / 9.0 - 0.5);
        vec2 imageUV = round((oldUV - blurOffset) * dim);
        
        sourceColor += imageLoad(sourceImage, clamp(ivec2(imageUV), ivec2(0, 0), ivec2(dim.x - 1,  dim.y - 1)));
    }
    sourceColor /= 10.0;

    vec2 imageUV = round((oldUV ) * dim);
    sourceColor.a = imageLoad(sourceImage, clamp(ivec2(imageUV), ivec2(0, 0), ivec2(dim.x - 1,  dim.y - 1))).a;
    imageStore(targetImage, ivec2(gl_GlobalInvocationID.xy), sourceColor);
}